{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "south-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy.linalg import inv\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-device",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affecting-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toeplitz_cov(n):\n",
    "    cov = toeplitz(np.exp(-(np.arange(n*1.0))**2/n))\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subjective-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(Pred,Real):\n",
    "    SSres = np.mean((Real-Pred)**2,0)\n",
    "    SStot = np.var(Real,0)\n",
    "    return np.nan_to_num(1-SSres/SStot)\n",
    "\n",
    "def ridge(X,Y,lmbda):\n",
    "    return np.dot(inv(X.T.dot(X)+lmbda*np.eye(X.shape[1])),X.T.dot(Y))\n",
    "\n",
    "def ridge_by_lambda(X, Y, Xval, Yval, lambdas):\n",
    "    error = np.zeros((lambdas.shape[0],Y.shape[1]))\n",
    "    for idx,lmbda in enumerate(lambdas):\n",
    "        weights = ridge(X,Y,lmbda)\n",
    "        error[idx] = 1 - R2(np.dot(Xval,weights),Yval)\n",
    "    return error\n",
    "\n",
    "def cross_val_ridge(train_features, train_data, n_splits=10, lambdas=np.array([10**i for i in range(-6, 10)])):\n",
    "    n_voxels = train_data.shape[1]\n",
    "    n_lambdas = lambdas.shape[0]\n",
    "    n_feats = train_features.shape[1]\n",
    "    r_cv = np.zeros((n_lambdas, n_voxels))\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    for icv, (trn, val) in enumerate(kf.split(train_data)):\n",
    "        cost = ridge_by_lambda(train_features[trn], train_data[trn], train_features[val], train_data[val], lambdas=lambdas)\n",
    "        r_cv += cost\n",
    "        \n",
    "    argmin_lambda = np.argmin(r_cv,axis = 0)\n",
    "    weights = np.zeros((n_feats,n_voxels))\n",
    "    for idx_lambda in range(lambdas.shape[0]):\n",
    "        idx_vox = argmin_lambda == idx_lambda\n",
    "        weights[:,idx_vox] = ridge(train_features, train_data[:,idx_vox],lambdas[idx_lambda])\n",
    "    min_lambdas = np.array([lambdas[i] for i in argmin_lambda])\n",
    "\n",
    "    return weights, min_lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunrise-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(X,Y):\n",
    "    return np.mean(zscore(X)*zscore(Y),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "geographic-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_ys(corrs, y_keys):\n",
    "    # Input: expects corrs to have repetition data stored in \n",
    "    # corrs['v1v2'][k] and/or corrs['v1p1'][k] and/or corrs['v2p1'][k] for k in y_keys.\n",
    "    # Output: ys and ys_std with computed means and stddevs for each k for easy error bar plotting.\n",
    "    ys, ys_std = {}, {}\n",
    "    for corr_type in corrs.keys(): # 'v1v2'/'v1p1'/'v2p1'\n",
    "        ys[corr_type], ys_std[corr_type] = [], []\n",
    "    \n",
    "    # Compute means and stddevs for easy error bar plotting\n",
    "    for k in y_keys:\n",
    "        for corr_type in corrs.keys(): # 'v1v2'/'v1p1'/'v2p1'\n",
    "            ys[corr_type].append(np.mean(np.array(corrs[corr_type][k])))\n",
    "            ys_std[corr_type].append(np.std(np.array(corrs[corr_type][k])))\n",
    "    return ys, ys_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-wells",
   "metadata": {},
   "source": [
    "### 1. Generate random features and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handy-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_and_weights(n, ms):\n",
    "    m1, m2, m3, m12 = ms\n",
    "    # Features\n",
    "    x1 = np.random.multivariate_normal(mean=np.zeros(m1), cov=toeplitz_cov(m1), size=(n,)) if m1>0 else np.array([]).reshape(n,0)\n",
    "    x2 = np.random.multivariate_normal(mean=np.zeros(m2), cov=toeplitz_cov(m2), size=(n,)) if m2>0 else np.array([]).reshape(n,0)\n",
    "    x3 = np.random.multivariate_normal(mean=np.zeros(m3), cov=toeplitz_cov(m3), size=(n,)) if m3>0 else np.array([]).reshape(n,0)\n",
    "    x12 = np.random.multivariate_normal(mean=np.zeros(m12), cov=toeplitz_cov(m12), size=(n,)) if m12>0 else np.array([]).reshape(n,0)\n",
    "    x = np.concatenate((x1, x2, x3, x12), axis=1) # x: (n, m1+m2+m3+m12)\n",
    "    \n",
    "    # Weights\n",
    "    w1 = np.random.rand(m1, 1)\n",
    "    w2 = np.random.rand(m2, 1)\n",
    "    w12 = np.random.rand(m12, 1)\n",
    "    return (x, x1, x2, x3, x12), (w1, w2, w12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-edinburgh",
   "metadata": {},
   "source": [
    "### 2. Generate voxel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prostate-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_voxels(n, ms, xs, ws, eps_stds, use_shared_information):\n",
    "    # Initialize noise\n",
    "    eps_std1, eps_std2, eps_std12 = eps_stds\n",
    "    eps1 = np.random.normal(loc=0.0, scale=eps_std1, size=(n, 1))\n",
    "    eps2 = np.random.normal(loc=0.0, scale=eps_std2, size=(n, 1))\n",
    "    eps12 = np.random.normal(loc=0.0, scale=eps_std12, size=(n, 1))\n",
    "    \n",
    "    # Generate voxel data\n",
    "    _, x1, x2, _, x12 = xs\n",
    "    w1, w2, w12 = ws\n",
    "    m1, m2, _, m12 = ms\n",
    "    if use_shared_information:\n",
    "        v12 = np.dot(x12, w12) if (m12 > 0) else np.zeros((n,1))\n",
    "        v1 = zscore(np.dot(x1, w1) + v12) + eps1 + eps12 if (m1 > 0) else zscore(v12) + eps1 + eps12\n",
    "        v2 = zscore(np.dot(x2, w2) + v12) + eps2 + eps12 if (m2 > 0) else zscore(v12) + eps2 + eps12\n",
    "    else:\n",
    "        v12 = None\n",
    "        v1 = zscore(np.dot(x1, w1)) + eps1 if (m1 > 0) else eps1\n",
    "        v2 = zscore(np.dot(x2, w2)) + eps2 if (m2 > 0) else eps2\n",
    "    return (v1, v2, v12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-amino",
   "metadata": {},
   "source": [
    "### 3. Combine everything to perform one experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "varied-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiment(n, ms, eps_stds, use_shared_information):\n",
    "    # Generate features, weights, voxel data\n",
    "    xs, ws = generate_features_and_weights(n, ms)\n",
    "    vs = generate_voxels(n, ms, xs, ws, eps_stds, use_shared_information)\n",
    "\n",
    "    # Estimate weights using ridge\n",
    "    x = xs[0]\n",
    "    v1, v2 = vs[0], vs[1]\n",
    "    estimated_w1, lambdas1 = cross_val_ridge(x, v1)\n",
    "    estimated_w2, lambdas2 = cross_val_ridge(x, v2)\n",
    "    \n",
    "    # Compute predictions\n",
    "    p1 = np.dot(x, estimated_w1)\n",
    "    p2 = np.dot(x, estimated_w2)\n",
    "                \n",
    "    # Compute relevant correlations\n",
    "    corr_v1v2 = corr(v1, v2)\n",
    "    corr_v1p1 = corr(v1, p1)\n",
    "    corr_v2p1 = corr(v2, p1)\n",
    "    corr_v2p2 = corr(v2, p2)\n",
    "    return corr_v1v2, corr_v1p1, corr_v2p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-membrane",
   "metadata": {},
   "source": [
    "# Debug Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This section is useful when you want to play around with parameter values, use the python debugger, etc.\n",
    "eps_std12 = 1.0\n",
    "m1, m2, m3, m12 = 3, 3, 4, 30\n",
    "all_eps_stds = [i*0.5 for i in range(7)] # only for eps_std1 and eps_std2\n",
    "n = 500 # no. of train samples\n",
    "m = 40 # total no. of features\n",
    "n_repetitions = 25\n",
    "use_shared_information = True\n",
    "\n",
    "corrs = {}\n",
    "corrs['v1v2'], corrs['v1p1'], corrs['v2p1'] = {}, {}, {}\n",
    "for eps_std1 in all_eps_stds:\n",
    "    s = time.time()\n",
    "    corrs['v1v2'][eps_std1], corrs['v1p1'][eps_std1], corrs['v2p1'][eps_std1] = {}, {}, {}\n",
    "    for eps_std2 in all_eps_stds:\n",
    "        corrs['v1v2'][eps_std1][eps_std2], corrs['v1p1'][eps_std1][eps_std2], corrs['v2p1'][eps_std1][eps_std2] = [], [], []\n",
    "        for i in range(n_repetitions):\n",
    "            ms = [m1, m2, m3, m12]\n",
    "            eps_stds = [eps_std1, eps_std2, eps_std12] # same standard deviation for all voxel noises\n",
    "            corr_v1v2, corr_v1p1, corr_v2p1 = perform_experiment(n, ms, eps_stds, use_shared_information)\n",
    "\n",
    "            corrs['v1v2'][eps_std1][eps_std2].append(corr_v1v2)\n",
    "            corrs['v1p1'][eps_std1][eps_std2].append(corr_v1p1)\n",
    "            corrs['v2p1'][eps_std1][eps_std2].append(corr_v2p1)\n",
    "    e = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot contour plots\n",
    "X, Y, Z_v1v2, Z_p1v2 = np.zeros((7,7)), np.zeros((7,7)), np.zeros((7,7)), np.zeros((7,7))\n",
    "for i, eps_stdx in enumerate(all_eps_stds):\n",
    "    for j, eps_stdy in enumerate(all_eps_stds):\n",
    "        X[i][j] = eps_stdx\n",
    "        Y[i][j] = eps_stdy\n",
    "        Z_v1v2[i][j] = np.mean(np.array(corrs['v1v2'][eps_stdx][eps_stdy]))\n",
    "        Z_p1v2[i][j] = np.mean(np.array(corrs['v2p1'][eps_stdx][eps_stdy]))\n",
    "\n",
    "plt.contourf(X, Y, Z_v1v2, cmap='RdGy')\n",
    "plt.title('cross-voxel correlation vs.\\nv1 noise, v2 noise')\n",
    "plt.xlabel('stddev of noise for v1')\n",
    "plt.ylabel('stddev of noise for v2')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.contourf(X, Y, Z_p1v2, cmap='RdGy')\n",
    "plt.title('cross-voxel predictivity vs.\\nv1 noise, v2 noise')\n",
    "plt.xlabel('stddev of noise for v1')\n",
    "plt.ylabel('stddev of noise for v2')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-carrier",
   "metadata": {},
   "source": [
    "# How Predictivity Varies with Different Noise Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Experiment Settings #\n",
    "#######################\n",
    "use_shared_information = True # TOGGLE: [True, False]\n",
    "\n",
    "n = 500 # no. of train samples\n",
    "m1, m2, m3, m12 = 10, 10, 10, 10 # no. of features\n",
    "n_repetitions = 100\n",
    "all_eps_stds = [i*0.25 for i in range(21)]\n",
    "\n",
    "corrs = {}\n",
    "corrs['v1p1'], corrs['v2p1'] = {}, {}\n",
    "\n",
    "################################################\n",
    "# Run multiple simulations at each noise level #\n",
    "################################################\n",
    "for eps_std in all_eps_stds:\n",
    "    print(\"eps_std={}\".format(eps_std))\n",
    "    corrs['v1p1'][eps_std], corrs['v2p1'][eps_std] = [], []\n",
    "    for i in range(n_repetitions):\n",
    "        ms = [m1, m2, m3, m12]\n",
    "        eps_stds = [eps_std, eps_std, eps_std] # same noise level for all voxels\n",
    "        _, corr_v1p1, corr_v2p1 = perform_experiment(n, ms, eps_stds, use_shared_information)\n",
    "\n",
    "        corrs['v1p1'][eps_std].append(corr_v1p1)\n",
    "        corrs['v2p1'][eps_std].append(corr_v2p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys, ys_std = get_plot_ys(corrs, all_eps_stds)\n",
    "plt.errorbar(all_eps_stds, ys['v1p1'], yerr=ys_std['v1p1'], fmt='o', label=\"corrs_v1p1\")\n",
    "plt.errorbar(all_eps_stds, ys['v2p1'], yerr=ys_std['v2p1'], fmt='o', label=\"corrs_v2p1\")\n",
    "plt.xlabel('stddev of noise')\n",
    "plt.ylabel('corr(prediction, voxel)')\n",
    "plt.ylim([-0.2, 1.2])\n",
    "plt.title('[No shared information]\\nsame-voxel & cross-voxel predictivity vs. noise')\n",
    "plt.legend()\n",
    "plt.savefig('spatial_generalization_experiments/plots/predictivity_generalization-vary_all_eps-m12_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('spatial_generalization_experiments/corrs/predictivity_generalization-vary_all_eps-m12_0.npy', corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys, ys_std = get_plot_ys(corrs, all_eps_stds)\n",
    "plt.errorbar(all_eps_stds, ys['v1p1'], yerr=ys_std['v1p1'], fmt='o', label=\"corrs_v1p1\")\n",
    "plt.errorbar(all_eps_stds, ys['v2p1'], yerr=ys_std['v2p1'], fmt='o', label=\"corrs_v2p1\")\n",
    "plt.xlabel('stddev of noise')\n",
    "plt.ylabel('corr(prediction, voxel)')\n",
    "plt.ylim([-0.2, 1.2])\n",
    "plt.title('[With shared information]\\nsame-voxel & cross-voxel predictivity vs. noise')\n",
    "plt.legend()\n",
    "plt.savefig('spatial_generalization_experiments/plots/predictivity_generalization-vary_all_eps-m12_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('spatial_generalization_experiments/corrs/predictivity_generalization-vary_all_eps-m12_0.npy', corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-vancouver",
   "metadata": {},
   "source": [
    "# How Predictivity Varies with Proportion of Shared Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Experiment Settings #\n",
    "#######################\n",
    "eps_std = 5. # TOGGLE: [0., 1., 2., 3., 4., 5.]\n",
    "m = 40 # total no. of features\n",
    "all_m12s = [i for i in range(0,m+5,5)]\n",
    "\n",
    "n = 500 # no. of train samples\n",
    "n_repetitions = 100\n",
    "use_shared_information = True\n",
    "\n",
    "corrs = {}\n",
    "corrs['v1p1'], corrs['v2p1'] = {}, {}\n",
    "\n",
    "#########################################\n",
    "# Run multiple simulations for each m12 #\n",
    "#########################################\n",
    "for m12 in all_m12s:\n",
    "    print(\"m12={}\".format(m12))\n",
    "    rem_m_size = (m-m12)//3\n",
    "    m1, m2, m3 = rem_m_size, rem_m_size, rem_m_size\n",
    "    m3 += (m-m12)%3\n",
    "    corrs['v1p1'][m12], corrs['v2p1'][m12] = [], []\n",
    "    for i in range(n_repetitions):\n",
    "        ms = [m1, m2, m3, m12]\n",
    "        eps_stds = [eps_std, eps_std, eps_std] # same noise level for all voxels\n",
    "        _, corr_v1p1, corr_v2p1 = perform_experiment(n, ms, eps_stds, use_shared_information)\n",
    "\n",
    "        corrs['v1p1'][m12].append(corr_v1p1)\n",
    "        corrs['v2p1'][m12].append(corr_v2p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys, ys_std = get_plot_ys(corrs, all_m12s)\n",
    "plt.errorbar([m12/m for m12 in all_m12s], ys['v1p1'], yerr=ys_std['v1p1'], fmt='o', label=\"corrs_v1p1\")\n",
    "plt.errorbar([m12/m for m12 in all_m12s], ys['v2p1'], yerr=ys_std['v2p1'], fmt='o', label=\"corrs_v2p1\")\n",
    "plt.xlabel('proportion of x12 in x')\n",
    "plt.ylabel('corr(prediction, voxel)')\n",
    "plt.ylim([-0.2, 1.2])\n",
    "plt.title('[eps_std={}] same-voxel and cross-voxel predictivity\\nvs.proportion of shared information'.format(eps_std))\n",
    "plt.legend()\n",
    "plt.savefig('spatial_generalization_experiments/plots/predictivity_generalization-vary_m12-all_eps_{}.png'.format(eps_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('spatial_generalization_experiments/corrs/predictivity_generalization-vary_m12-all_eps_{}.npy'.format(eps_std), corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-screening",
   "metadata": {},
   "source": [
    "# How Predictivity Varies with Noise Levels Per Voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-insert",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# Experiment Settings #\n",
    "#######################\n",
    "eps_std12 = 2.0 # NOTE: Chosen randomly. Might be worth experimenting with this.\n",
    "all_m12s = [0, 10, 20, 30]\n",
    "all_eps_stds = [i*0.25 for i in range(21)] # only for eps_std1 and eps_std2\n",
    "\n",
    "n = 500 # no. of train samples\n",
    "m = 40 # total no. of features\n",
    "n_repetitions = 100\n",
    "use_shared_information = True\n",
    "\n",
    "corrs = {}\n",
    "\n",
    "########################################################################\n",
    "# For each m12, run multiple simulations per (eps_std1, eps_std2) pair #\n",
    "########################################################################\n",
    "for m12 in all_m12s:\n",
    "    print(\"m12={}\".format(m12))\n",
    "    rem_m_size = (m-m12)//3\n",
    "    m1, m2, m3 = rem_m_size, rem_m_size, rem_m_size\n",
    "    m3 += (m-m12)%3\n",
    "    corrs[m12] = {}\n",
    "    corrs[m12]['v1v2'], corrs[m12]['v1p1'], corrs[m12]['v2p1'] = {}, {}, {}\n",
    "    \n",
    "    for eps_std1 in all_eps_stds:\n",
    "        s = time.time()\n",
    "        corrs[m12]['v1v2'][eps_std1], corrs[m12]['v1p1'][eps_std1], corrs[m12]['v2p1'][eps_std1] = {}, {}, {}\n",
    "        for eps_std2 in all_eps_stds:\n",
    "            corrs[m12]['v1v2'][eps_std1][eps_std2], corrs[m12]['v1p1'][eps_std1][eps_std2], corrs[m12]['v2p1'][eps_std1][eps_std2] = [], [], []\n",
    "            for i in range(n_repetitions):\n",
    "                ms = [m1, m2, m3, m12]\n",
    "                eps_stds = [eps_std1, eps_std2, eps_std12] # same standard deviation for all voxel noises\n",
    "                corr_v1v2, corr_v1p1, corr_v2p1 = perform_experiment(n, ms, eps_stds, use_shared_information)\n",
    "\n",
    "                corrs[m12]['v1v2'][eps_std1][eps_std2].append(corr_v1v2)\n",
    "                corrs[m12]['v1p1'][eps_std1][eps_std2].append(corr_v1p1)\n",
    "                corrs[m12]['v2p1'][eps_std1][eps_std2].append(corr_v2p1)\n",
    "        e = time.time()\n",
    "        print(\"Time Taken for eps_std1={}: {}s\".format(eps_std1, e-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-vietnamese",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(21,7))\n",
    "for col in range(4):\n",
    "    m12 = all_m12s[col]\n",
    "    # Format data for easy 2D plotting\n",
    "    X, Y, Z_v1v2, Z_p1v2 = np.zeros((21,21)), np.zeros((21,21)), np.zeros((21,21)), np.zeros((21,21))\n",
    "    for i, eps_stdx in enumerate(all_eps_stds):\n",
    "        for j, eps_stdy in enumerate(all_eps_stds):\n",
    "            X[i][j] = eps_stdx\n",
    "            Y[i][j] = eps_stdy\n",
    "            Z_v1v2[i][j] = np.mean(np.array(corrs[m12]['v1v2'][eps_stdx][eps_stdy]))\n",
    "            Z_p1v2[i][j] = np.mean(np.array(corrs[m12]['v2p1'][eps_stdx][eps_stdy]))\n",
    "    # Plot contour plot\n",
    "    ax1 = axs[0][col].contourf(X, Y, Z_v1v2, cmap='RdBu_r', vmin=0, vmax=1, levels=[0.1*i for i in range(11)])\n",
    "    ax2 = axs[1][col].contourf(X, Y, Z_p1v2, cmap='RdGy_r', vmin=0, vmax=1, levels=[0.1*i for i in range(11)])\n",
    "fig.colorbar(ax1, ax=axs[0, :])\n",
    "fig.colorbar(ax2, ax=axs[1, :])\n",
    "\n",
    "ylabels = ['corr(v1,v2)', 'corr(p1,v2)']\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.set(xlabel='m12={}'.format(all_m12s[i%4]), ylabel=ylabels[i//4])\n",
    "        \n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "plt.savefig('spatial_generalization_experiments/plots/predictivity_connectivity-vary_m12-vary_eps1_eps2-eps12_{}.png',format(eps_std12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('spatial_generalization_experiments/corrs/predictivity_connectivity-vary_m12-vary_eps1_eps2-eps12_{}.npy'.format(eps_std12), corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-clark",
   "metadata": {},
   "source": [
    "# Advantage of inspecting generalization over connectivity+predictivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-delicious",
   "metadata": {},
   "source": [
    "### 2.1 Generate voxel data with alpha multiplier \n",
    "(as depicted in slide 25: https://docs.google.com/presentation/d/1mW-LLlWE9fC4xKQJoPvqNHbixVhwKYs86IIic-Y6W-k/edit#slide=id.gcf5583fd7a_0_45)\n",
    "* <u>NOTE:</u> For all alpha, \n",
    "$$ m_1=m_2=m_3=m_{12}=10 $$\n",
    "$$ \\epsilon_{1}=\\epsilon_{2}=\\epsilon_{12}=1.0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "color-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_voxels_with_alpha(n, xs, ws, alpha):\n",
    "    # Initialize noise\n",
    "    eps_std1, eps_std2, eps_std12 = 1.0, 1.0, 1.0 # As mentioned in NOTE above.\n",
    "    eps1 = np.random.normal(loc=0.0, scale=eps_std1, size=(n, 1))\n",
    "    eps2 = np.random.normal(loc=0.0, scale=eps_std2, size=(n, 1))\n",
    "    eps12 = np.random.normal(loc=0.0, scale=eps_std12, size=(n, 1))\n",
    "    \n",
    "    # Generate voxel data\n",
    "    _, x1, x2, _, x12 = xs\n",
    "    w1, w2, w12 = ws\n",
    "    \n",
    "    v12 = np.dot(x12, w12)\n",
    "    v1 = (1-alpha)*zscore(np.dot(x1, w1)) + alpha*zscore(v12) + alpha*eps1 + (1-alpha)*eps12\n",
    "    v2 = (1-alpha)*zscore(np.dot(x2, w2)) + alpha*zscore(v12) + alpha*eps2 + (1-alpha)*eps12\n",
    "    return (v1, v2, v12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "monthly-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiment_with_alpha(n, alpha):\n",
    "    # Generate features, weights, voxel data\n",
    "    ms = [10, 10, 10, 10] # As mentioned in NOTE above. This is important later to ensure zscore can be done separately.\n",
    "    xs, ws = generate_features_and_weights(n, ms)\n",
    "    vs = generate_voxels_with_alpha(n, xs, ws, alpha)\n",
    "\n",
    "    # Estimate weights using ridge\n",
    "    x = xs[0]\n",
    "    v1, v2 = vs[0], vs[1]\n",
    "    estimated_w1, lambdas1 = cross_val_ridge(x, v1)\n",
    "    estimated_w2, lambdas2 = cross_val_ridge(x, v2)\n",
    "    \n",
    "    # Compute predictions\n",
    "    p1 = np.dot(x, estimated_w1)\n",
    "    p2 = np.dot(x, estimated_w2)\n",
    "                \n",
    "    # Compute relevant correlations\n",
    "    corr_v1v2 = corr(v1, v2)\n",
    "    corr_v1p1 = corr(v1, p1)\n",
    "    corr_v2p1 = corr(v2, p1)\n",
    "    corr_v2p2 = corr(v2, p2)\n",
    "    return corr_v1v2, corr_v1p1, corr_v2p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "opening-disease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.0\n",
      "alpha=0.1\n",
      "alpha=0.2\n",
      "alpha=0.30000000000000004\n",
      "alpha=0.4\n",
      "alpha=0.5\n",
      "alpha=0.6000000000000001\n",
      "alpha=0.7000000000000001\n",
      "alpha=0.8\n",
      "alpha=0.9\n",
      "alpha=1.0\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Experiment Settings #\n",
    "#######################\n",
    "all_alphas = [0.1*i for i in range(11)]\n",
    "n = 500 # no. of train samples\n",
    "n_repetitions = 100\n",
    "\n",
    "corrs = {}\n",
    "corrs['v1v2'], corrs['v1p1'], corrs['v2p1'] = {}, {}, {}\n",
    "\n",
    "#########################################\n",
    "# Run multiple simulations for each m12 #\n",
    "#########################################\n",
    "for alpha in all_alphas:\n",
    "    print(\"alpha={}\".format(alpha))\n",
    "    corrs['v1v2'][alpha], corrs['v1p1'][alpha], corrs['v2p1'][alpha] = [], [], []\n",
    "    for i in range(n_repetitions):\n",
    "        corr_v1v2, corr_v1p1, corr_v2p1 = perform_experiment_with_alpha(n, alpha)\n",
    "        corrs['v1v2'][alpha].append(corr_v1v2)\n",
    "        corrs['v1p1'][alpha].append(corr_v1p1)\n",
    "        corrs['v2p1'][alpha].append(corr_v2p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tight-scholar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ys, ys_std = get_plot_ys(corrs, all_alphas)\n",
    "plt.errorbar(all_alphas, ys['v1v2'], yerr=ys_std['v1v2'], fmt='o', label=\"corrs_v1v2\")\n",
    "plt.errorbar(all_alphas, ys['v1p1'], yerr=ys_std['v1p1'], fmt='o', label=\"corrs_v1p1\")\n",
    "plt.errorbar(all_alphas, ys['v2p1'], yerr=ys_std['v2p1'], fmt='o', label=\"corrs_v2p1\")\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('corr')\n",
    "plt.ylim([-0.2, 1.2])\n",
    "plt.title('Tracking connectivity, predictivity and\\ngeneralization at different alpha levels')\n",
    "plt.legend()\n",
    "plt.savefig('spatial_generalization_experiments/plots/connectivity_predictivity_generalization-vary_alpha-m12_10-all_eps_1.0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "medium-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('spatial_generalization_experiments/corrs/connectivity_predictivity_generalization-vary_alpha-m12_10-all_eps_1.0.npy', corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-transport",
   "metadata": {},
   "source": [
    "# Old Code Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how corr(v1,p1) as we vary shared noise vs. v1 specific noise \n",
    "#(we expect same effect from both noises for corr(v1,p1) so circular patter makes sense)\n",
    "all_eps_std12s = [0.0, 1.0, 2.0]\n",
    "eps_std1s = [i*0.25 for i in range(21)]\n",
    "\n",
    "X, Y, Z_v1p1 = np.zeros((len(eps_std1s),len(all_eps_std12s))), np.zeros((len(eps_std1s),len(all_eps_std12s))), np.zeros((len(eps_std1s),len(all_eps_std12s)))\n",
    "for j, eps_std12 in enumerate(all_eps_std12s):\n",
    "    corrs = np.load('spatial_generalization_experiments/corrs/predictivity_connectivity-vary_m12-vary_eps1_eps2-eps12_{}.npy'.format(eps_std12), allow_pickle=True).item()\n",
    "    for i, eps_std1 in enumerate(eps_std1s):\n",
    "        X[i][j] = eps_std1\n",
    "        Y[i][j] = eps_std12\n",
    "        Z_v1p1[i][j] = np.mean(np.array(corrs[0]['v1p1'][eps_std1][0.0]))\n",
    "# Plot contour plot\n",
    "plt.contourf(X, Y, Z_v1p1, cmap='PuOr', vmin=0, vmax=1, levels=[0.1*i for i in range(11)])\n",
    "plt.colorbar()\n",
    "plt.ylabel('eps_12 stddev')\n",
    "plt.xlabel('eps_1 stddev')\n",
    "plt.yticks([0.0,1.0,2.0])\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('spatial_generalization_experiments/plots/predictivity-vary_eps1_eps12.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-premises",
   "metadata": {},
   "source": [
    "## How Predictivity Varies with Noise Levels (No Repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random features & weights\n",
    "\n",
    "n = 50 # no. of train samples\n",
    "m1, m2, m3, m12 = 10, 10, 10, 10 # no. of features\n",
    "\n",
    "x1 = np.random.multivariate_normal(mean=np.random.rand(m1), cov=toeplitz_cov(m1), size=(n,))\n",
    "x2 = np.random.multivariate_normal(mean=np.random.rand(m2), cov=toeplitz_cov(m2), size=(n,))\n",
    "x3 = np.random.multivariate_normal(mean=np.random.rand(m3), cov=toeplitz_cov(m3), size=(n,))\n",
    "x12 = np.random.multivariate_normal(mean=np.random.rand(m12), cov=toeplitz_cov(m12), size=(n,))\n",
    "x = np.concatenate((x1, x2, x3, x12), axis=1) # x: (n, m1+m2+m3+m12)\n",
    "\n",
    "w1 = np.random.rand(m1, 1)\n",
    "w2 = np.random.rand(m2, 1)\n",
    "w12 = np.random.rand(m12, 1)\n",
    "\n",
    "# Generate voxel data and use ridge for prediction\n",
    "\n",
    "eps_stds = [i*0.05 for i in range(21)]\n",
    "use_eps1, use_eps2, use_eps12 = True, True, True\n",
    "use_shared_information = True\n",
    "\n",
    "corrs_v1p1, corrs_v2p2, corrs_v1p2, corrs_v2p1 = [], [], [], []\n",
    "for eps_std in eps_stds:\n",
    "    # Initialize noise\n",
    "    eps1 = np.random.normal(loc=0.0, scale=eps_std, size=(n, 1)) if use_eps1 else 0\n",
    "    eps2 = np.random.normal(loc=0.0, scale=eps_std, size=(n, 1)) if use_eps2 else 0\n",
    "    eps12 = np.random.normal(loc=0.0, scale=eps_std, size=(n, 1)) if use_eps12 else 0\n",
    "    \n",
    "    # Generate voxel data\n",
    "    if use_shared_information:\n",
    "        v12 = np.dot(x12, w12) + eps12\n",
    "        v1 = np.dot(x1, w1) + v12 + eps1\n",
    "        v2 = np.dot(x2, w2) + v12 + eps2\n",
    "    else:\n",
    "        v12 = np.dot(x12, w12) + eps12\n",
    "        v1 = np.dot(x1, w1) + eps1\n",
    "        v2 = np.dot(x2, w2) + eps2\n",
    "    \n",
    "    # Estimate weights using ridge\n",
    "    estimated_w1, lambdas1 = cross_val_ridge(x, v1)\n",
    "    estimated_w2, lambdas2 = cross_val_ridge(x, v2)\n",
    "    # Compute predictions\n",
    "    p1 = np.dot(x, estimated_w1)\n",
    "    p2 = np.dot(x, estimated_w2)\n",
    "    \n",
    "    # Assess predictions\n",
    "    corr_v1p1 = corr(v1, p1)\n",
    "    corr_v2p2 = corr(v2, p2)\n",
    "    # Assess predictivity across voxels\n",
    "    corr_v1p2 = corr(v1, p2)\n",
    "    corr_v2p1 = corr(v2, p1)\n",
    "    \n",
    "    corrs_v1p1.append(corr_v1p1)\n",
    "    corrs_v2p2.append(corr_v2p2)\n",
    "    corrs_v1p2.append(corr_v1p2)\n",
    "    corrs_v2p1.append(corr_v2p1)# Generate random features & weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eps_stds, corrs_v1p1, label=\"corrs_v1p1\")\n",
    "plt.plot(eps_stds, corrs_v2p2, label=\"corrs_v2p2\")\n",
    "plt.plot(eps_stds, corrs_v1p2, label=\"corrs_v1p2\")\n",
    "plt.plot(eps_stds, corrs_v2p1, label=\"corrs_v2p1\")\n",
    "plt.xlabel('noise scales')\n",
    "plt.ylabel('corr(prediction, voxel)')\n",
    "plt.ylim([-0.2, 1.2])\n",
    "plt.title('Assessing same-voxel and cross-voxel predictivity for different noise levels (Without shared information)')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eps_stds, corrs_v1p1, label=\"corrs_v1p1\")\n",
    "plt.plot(eps_stds, corrs_v2p2, label=\"corrs_v2p2\")\n",
    "plt.plot(eps_stds, corrs_v1p2, label=\"corrs_v1p2\")\n",
    "plt.plot(eps_stds, corrs_v2p1, label=\"corrs_v2p1\")\n",
    "plt.xlabel('noise scales')\n",
    "plt.ylabel('corr(prediction, voxel)')\n",
    "plt.ylim([-0.2, 1.2])\n",
    "plt.title('Assessing same-voxel and cross-voxel predictivity for different noise levels (With shared information)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-quality",
   "metadata": {},
   "source": [
    "## How Predictivity Varies with Proportion of Shared Information (No Repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50 # no. of train samples\n",
    "m = 40 # total no. of features\n",
    "\n",
    "corrs_v1p1, corrs_v2p2, corrs_v1p2, corrs_v2p1 = [], [], [], []\n",
    "m12s = [i for i in range(0,m-5,5)]\n",
    "use_shared_information = True\n",
    "\n",
    "for m12 in m12s:\n",
    "    # Generate random features & weights\n",
    "    \n",
    "    rem_m_size = (m-m12)//3\n",
    "    m1, m2, m3 = rem_m_size, rem_m_size, rem_m_size\n",
    "    m3 += (m-m12)%3\n",
    "\n",
    "    x1 = np.random.multivariate_normal(mean=np.random.rand(m1), cov=toeplitz_cov(m1), size=(n,))\n",
    "    x2 = np.random.multivariate_normal(mean=np.random.rand(m2), cov=toeplitz_cov(m2), size=(n,))\n",
    "    x3 = np.random.multivariate_normal(mean=np.random.rand(m3), cov=toeplitz_cov(m3), size=(n,))\n",
    "    x12 = np.random.multivariate_normal(mean=np.random.rand(m12), cov=toeplitz_cov(m12), size=(n,)) if m12 > 0 else np.array([]).reshape(n,0)\n",
    "    x = np.concatenate((x1, x2, x3, x12), axis=1) # x: (n, m1+m2+m3+m12)\n",
    "\n",
    "    w1 = np.random.rand(m1, 1)\n",
    "    w2 = np.random.rand(m2, 1)\n",
    "    w12 = np.random.rand(m12, 1)\n",
    "\n",
    "    # Generate voxel data and use ridge for prediction\n",
    "    \n",
    "    eps_std = 0.5\n",
    "    # Initialize noise\n",
    "    eps1 = np.random.normal(loc=0.0, scale=eps_std, size=(n, 1))\n",
    "    eps2 = np.random.normal(loc=0.0, scale=eps_std, size=(n, 1))\n",
    "    eps12 = np.random.normal(loc=0.0, scale=eps_std, size=(n, 1))\n",
    "\n",
    "    # Generate voxel data\n",
    "    if use_shared_information:\n",
    "        v12 = np.dot(x12, w12) + eps12\n",
    "        v1 = np.dot(x1, w1) + v12 + eps1\n",
    "        v2 = np.dot(x2, w2) + v12 + eps2\n",
    "    else:\n",
    "        v12 = np.dot(x12, w12) + eps12\n",
    "        v1 = np.dot(x1, w1) + eps1\n",
    "        v2 = np.dot(x2, w2) + eps2\n",
    "\n",
    "    # Estimate weights using ridge\n",
    "    estimated_w1, lambdas1 = cross_val_ridge(x, v1)\n",
    "    estimated_w2, lambdas2 = cross_val_ridge(x, v2)\n",
    "    # Compute predictions\n",
    "    p1 = np.dot(x, estimated_w1)\n",
    "    p2 = np.dot(x, estimated_w2)\n",
    "\n",
    "    # Assess predictions\n",
    "    corr_v1p1 = corr(v1, p1)\n",
    "    corr_v2p2 = corr(v2, p2)\n",
    "    # Assess predictivity across voxels\n",
    "    corr_v1p2 = corr(v1, p2)\n",
    "    corr_v2p1 = corr(v2, p1)\n",
    "\n",
    "    corrs_v1p1.append(corr_v1p1)\n",
    "    corrs_v2p2.append(corr_v2p2)\n",
    "    corrs_v1p2.append(corr_v1p2)\n",
    "    corrs_v2p1.append(corr_v2p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([m12/m for m12 in m12s], corrs_v1p1, label=\"corrs_v1p1\")\n",
    "plt.plot([m12/m for m12 in m12s], corrs_v2p2, label=\"corrs_v2p2\")\n",
    "plt.plot([m12/m for m12 in m12s], corrs_v1p2, label=\"corrs_v1p2\")\n",
    "plt.plot([m12/m for m12 in m12s], corrs_v2p1, label=\"corrs_v2p1\")\n",
    "plt.xlabel('proportion of m12/m in x')\n",
    "plt.ylabel('corr(prediction, voxel)')\n",
    "plt.ylim([-0.2, 1.2])\n",
    "plt.title('Assessing same-voxel and cross-voxel predictivity for\\ndifferent proportions of shared information')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_macos",
   "language": "python",
   "name": "pytorch_macos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
